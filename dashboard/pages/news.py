"""
ë‰´ìŠ¤ í”¼ë“œ í˜ì´ì§€
ìˆ˜ì§‘ëœ ì‹œì¥ ë‰´ìŠ¤ë¥¼ ê°ì„± ì ìˆ˜ì™€ í•¨ê»˜ í‘œì‹œí•©ë‹ˆë‹¤.
"""
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from datetime import datetime, timedelta

import streamlit as st

from database.connection import get_db
from database.models import MarketNews
from dashboard.utils import safe_div, CACHE_TTL_SHORT

try:
    from config.tickers import get_tickers_by_index
    _HAS_TICKERS = True
except ImportError:
    _HAS_TICKERS = False


@st.cache_data(ttl=CACHE_TTL_SHORT)
def _load_news(days: int) -> list[dict]:
    """ë‰´ìŠ¤ ì „ì²´ë¥¼ ìºì‹œë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    cutoff = datetime.now() - timedelta(days=days)
    try:
        with get_db() as db:
            rows = (
                db.query(MarketNews)
                .filter(MarketNews.published_at >= cutoff)
                .order_by(MarketNews.published_at.desc())
                .limit(200)
                .all()
            )
            return [
                {
                    "ticker": r.ticker or "ì‹œì¥ ì „ë°˜",
                    "title": r.title,
                    "summary": r.summary or "",
                    "url": r.url,
                    "source": r.source or "N/A",
                    "sentiment": r.sentiment,
                    "published_at": r.published_at.strftime("%Y-%m-%d %H:%M") if r.published_at else "N/A",
                }
                for r in rows
            ]
    except Exception:
        return []


def _sentiment_badge(sentiment: float | None) -> str:
    """ê°ì„± ì ìˆ˜ë¥¼ ë°°ì§€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if sentiment is None:
        return "âšª N/A"
    if sentiment > 0.2:
        return f"ğŸŸ¢ {sentiment:+.2f}"
    elif sentiment < -0.2:
        return f"ğŸ”´ {sentiment:+.2f}"
    else:
        return f"ğŸŸ¡ {sentiment:+.2f}"


def _render_news_list(news_list: list[dict], search_input: str):
    """ë‰´ìŠ¤ ëª©ë¡ ë Œë”ë§ â€” ë‹¨ì¼ í•¨ìˆ˜ë¡œ ì½”ë“œ ì¤‘ë³µ ì œê±°"""
    # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì ìš©
    if search_input:
        news_list = [n for n in news_list if search_input in n["ticker"].upper()]

    if not news_list:
        st.info("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # â”€â”€ ê°ì„± ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sentiments = [n["sentiment"] for n in news_list if n["sentiment"] is not None]
    if sentiments:
        avg_sent = safe_div(sum(sentiments), len(sentiments))
        pos_count = sum(1 for s in sentiments if s > 0.2)
        neg_count = sum(1 for s in sentiments if s < -0.2)

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ì „ì²´ ë‰´ìŠ¤", f"{len(news_list)}ê±´")
        c2.metric("í‰ê·  ê°ì„±", f"{avg_sent:+.3f}")
        c3.metric("ê¸ì • ë‰´ìŠ¤", f"{pos_count}ê±´")
        c4.metric("ë¶€ì • ë‰´ìŠ¤", f"{neg_count}ê±´")
        st.divider()

    # â”€â”€ ë‰´ìŠ¤ ëª©ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for n in news_list:
        sentiment_text = _sentiment_badge(n["sentiment"])

        with st.container():
            col_badge, col_content = st.columns([1, 7])

            with col_badge:
                st.markdown(f"**{n['ticker']}**")
                st.markdown(sentiment_text)
                st.caption(n["published_at"])

            with col_content:
                if n.get("url"):
                    st.markdown(f"**[{n['title']}]({n['url']})**")
                else:
                    st.markdown(f"**{n['title']}**")

                if n["summary"]:
                    summary_text = n["summary"][:200]
                    if len(n["summary"]) > 200:
                        summary_text += "..."
                    st.markdown(f"<small>{summary_text}</small>", unsafe_allow_html=True)
                st.caption(f"ì¶œì²˜: {n['source']}")

            st.divider()


def render():
    st.header("ğŸ“° ë‰´ìŠ¤ í”¼ë“œ")

    # â”€â”€ í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    filter_col, days_col = st.columns([3, 1])

    with days_col:
        days = st.selectbox("ê¸°ê°„", [1, 3, 7, 14, 30], index=2, key="news_days",
                            format_func=lambda d: f"ìµœê·¼ {d}ì¼")

    with filter_col:
        search_input = st.text_input(
            "ì¢…ëª© ê²€ìƒ‰",
            placeholder="í‹°ì»¤ ì…ë ¥ (ì˜ˆ: AAPL)...",
            key="news_search",
        ).strip().upper()

    # ì „ì²´ ë‰´ìŠ¤ ë¡œë“œ (í•œ ë²ˆë§Œ)
    all_news = _load_news(days)

    # ì¸ë±ìŠ¤ íƒ­
    if _HAS_TICKERS:
        tab_all, tab_nasdaq, tab_sp500 = st.tabs(["ì „ì²´", "NASDAQ100", "S&P500"])
    else:
        tab_all = st.container()
        tab_nasdaq = tab_sp500 = None

    with tab_all:
        _render_news_list(all_news, search_input)

    if _HAS_TICKERS and tab_nasdaq and tab_sp500:
        with tab_nasdaq:
            nasdaq_tickers = get_tickers_by_index("NASDAQ100")
            filtered = [n for n in all_news if n["ticker"] in nasdaq_tickers]
            _render_news_list(filtered, search_input)

        with tab_sp500:
            sp500_tickers = get_tickers_by_index("SP500")
            filtered = [n for n in all_news if n["ticker"] in sp500_tickers]
            _render_news_list(filtered, search_input)

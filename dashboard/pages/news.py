"""
ë‰´ìŠ¤ í”¼ë“œ í˜ì´ì§€
ìˆ˜ì§‘ëœ ì‹œì¥ ë‰´ìŠ¤ë¥¼ ê°ì„± ì ìˆ˜ì™€ í•¨ê»˜ í‘œì‹œí•©ë‹ˆë‹¤.
"""
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from datetime import datetime, timedelta

import streamlit as st
import pandas as pd

from config.settings import settings
from database.connection import get_db
from database.models import MarketNews

try:
    from config.tickers import get_tickers_by_index
    _HAS_TICKERS = True
except ImportError:
    _HAS_TICKERS = False


@st.cache_data(ttl=120)
def _load_news(ticker_filter: str | None, days: int) -> list[dict]:
    """ë‰´ìŠ¤ ë°ì´í„°ë¥¼ 120ì´ˆ ìºì‹œë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    cutoff = datetime.now() - timedelta(days=days)

    with get_db() as db:
        query = db.query(MarketNews).filter(MarketNews.published_at >= cutoff)
        if ticker_filter and ticker_filter != "ì „ì²´":
            query = query.filter(MarketNews.ticker == ticker_filter)
        rows = query.order_by(MarketNews.published_at.desc()).limit(100).all()

        return [
            {
                "ticker": r.ticker or "ì‹œì¥ ì „ë°˜",
                "title": r.title,
                "summary": r.summary or "",
                "url": r.url,
                "source": r.source or "N/A",
                "sentiment": r.sentiment,
                "published_at": r.published_at.strftime("%Y-%m-%d %H:%M") if r.published_at else "N/A",
            }
            for r in rows
        ]


def _sentiment_badge(sentiment: float | None) -> str:
    """ê°ì„± ì ìˆ˜ë¥¼ ë°°ì§€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if sentiment is None:
        return "âšª N/A"
    if sentiment > 0.2:
        return f"ğŸŸ¢ {sentiment:+.2f}"
    elif sentiment < -0.2:
        return f"ğŸ”´ {sentiment:+.2f}"
    else:
        return f"ğŸŸ¡ {sentiment:+.2f}"


def render():
    st.header("ğŸ“° ë‰´ìŠ¤ í”¼ë“œ")

    # â”€â”€ í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    filter_col, days_col = st.columns([3, 1])

    with days_col:
        days = st.selectbox("ê¸°ê°„", [1, 3, 7, 14, 30], index=2, key="news_days",
                            format_func=lambda d: f"ìµœê·¼ {d}ì¼")

    with filter_col:
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰ + ì¸ë±ìŠ¤ íƒ­ í•„í„°
        search_input = st.text_input(
            "ì¢…ëª© ê²€ìƒ‰",
            placeholder="í‹°ì»¤ ì…ë ¥ (ì˜ˆ: AAPL)...",
            key="news_search",
        ).strip().upper()

    # ì¸ë±ìŠ¤ íƒ­
    if _HAS_TICKERS:
        tab_all, tab_nasdaq, tab_sp500 = st.tabs(["ì „ì²´", "NASDAQ100", "S&P500"])
    else:
        tab_all = st.container()
        tab_nasdaq = tab_sp500 = None

    def _render_news_tab(ticker_filter: str | None):
        news_list = _load_news(ticker_filter, days)

        if not news_list:
            st.info("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. `python main.py fetch`ë¥¼ ì‹¤í–‰í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
            return

        # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì ìš©
        if search_input:
            news_list = [n for n in news_list if search_input in n["ticker"].upper()]

        # â”€â”€ ê°ì„± ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        sentiments = [n["sentiment"] for n in news_list if n["sentiment"] is not None]
        if sentiments:
            avg_sent = sum(sentiments) / len(sentiments)
            pos_count = sum(1 for s in sentiments if s > 0.2)
            neg_count = sum(1 for s in sentiments if s < -0.2)

            c1, c2, c3, c4 = st.columns(4)
            c1.metric("ì „ì²´ ë‰´ìŠ¤", f"{len(news_list)}ê±´")
            c2.metric("í‰ê·  ê°ì„±", f"{avg_sent:+.3f}")
            c3.metric("ê¸ì • ë‰´ìŠ¤", f"{pos_count}ê±´")
            c4.metric("ë¶€ì • ë‰´ìŠ¤", f"{neg_count}ê±´")
            st.divider()

        # â”€â”€ ë‰´ìŠ¤ ëª©ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for n in news_list:
            sentiment_text = _sentiment_badge(n["sentiment"])

            with st.container():
                col_badge, col_content = st.columns([1, 7])

                with col_badge:
                    st.markdown(f"**{n['ticker']}**")
                    st.markdown(sentiment_text)
                    st.caption(n["published_at"])

                with col_content:
                    if n.get("url"):
                        st.markdown(f"**[{n['title']}]({n['url']})**")
                    else:
                        st.markdown(f"**{n['title']}**")

                    if n["summary"]:
                        st.markdown(f"<small>{n['summary'][:200]}{'...' if len(n['summary']) > 200 else ''}</small>",
                                    unsafe_allow_html=True)
                    st.caption(f"ì¶œì²˜: {n['source']}")

                st.divider()

    with tab_all:
        _render_news_tab(None)

    if _HAS_TICKERS and tab_nasdaq and tab_sp500:
        # NASDAQ100 íƒ­: í•´ë‹¹ ì¸ë±ìŠ¤ ì¢…ëª©ë§Œ í•„í„°ë§
        with tab_nasdaq:
            nasdaq_tickers = get_tickers_by_index("NASDAQ100")
            # DBì—ì„œ ì¢…ëª©ë³„ í•„í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ì „ì²´ ë¡œë“œ í›„ íƒ­ì—ì„œ í•„í„°
            news_all = _load_news(None, days)
            if news_all:
                filtered = [n for n in news_all if n["ticker"] in nasdaq_tickers]
                if search_input:
                    filtered = [n for n in filtered if search_input in n["ticker"].upper()]
                if not filtered:
                    st.info("NASDAQ100 ì¢…ëª© ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    for n in filtered:
                        with st.container():
                            col_badge, col_content = st.columns([1, 7])
                            with col_badge:
                                st.markdown(f"**{n['ticker']}**")
                                st.markdown(_sentiment_badge(n["sentiment"]))
                                st.caption(n["published_at"])
                            with col_content:
                                if n.get("url"):
                                    st.markdown(f"**[{n['title']}]({n['url']})**")
                                else:
                                    st.markdown(f"**{n['title']}**")
                                if n["summary"]:
                                    st.markdown(f"<small>{n['summary'][:200]}</small>", unsafe_allow_html=True)
                                st.caption(f"ì¶œì²˜: {n['source']}")
                            st.divider()
            else:
                st.info("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with tab_sp500:
            sp500_tickers = get_tickers_by_index("SP500")
            news_all = _load_news(None, days)
            if news_all:
                filtered = [n for n in news_all if n["ticker"] in sp500_tickers]
                if search_input:
                    filtered = [n for n in filtered if search_input in n["ticker"].upper()]
                if not filtered:
                    st.info("S&P500 ì¢…ëª© ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    for n in filtered:
                        with st.container():
                            col_badge, col_content = st.columns([1, 7])
                            with col_badge:
                                st.markdown(f"**{n['ticker']}**")
                                st.markdown(_sentiment_badge(n["sentiment"]))
                                st.caption(n["published_at"])
                            with col_content:
                                if n.get("url"):
                                    st.markdown(f"**[{n['title']}]({n['url']})**")
                                else:
                                    st.markdown(f"**{n['title']}**")
                                if n["summary"]:
                                    st.markdown(f"<small>{n['summary'][:200]}</small>", unsafe_allow_html=True)
                                st.caption(f"ì¶œì²˜: {n['source']}")
                            st.divider()
            else:
                st.info("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
